#!/usr/bin/python
"""Group bins and apply functions.

A set of functions for grouping data on one or two dimensional bins and
efficiently apply functions to resulting groups.  To be used with Dask
delayed for multicore and distributed processing.

Todo:
    * Rewrite as a couple of class instead of disjointed functions
    * Add error checking
    * Fix index problem at row 0 and -1
    * Implement sparse arrays for 2D bin grid
"""

import numpy as np
#import numba as nb
import scipy.constants


import dask.array as da
import dask
import xarray as xr
from daskms import xds_from_table, xds_from_ms


#@nb.jit(nopython=True, nogil=True, cache=True)
def groupby_nd(bins, init_index:int=0) -> tuple:
    '''
    Performs a groupby operation on two bin parameters and returns the list
    of indicies for mapping the unique groups to their positions.

    Parameters
    ----------
    bins: array-like
        An array or tuple containing two lists of bins values for two the
        parameters to be binned.
    init_index: int, optional
        Starting value for the indicies to use when iterating or chunking
        large lists of bins.

    Returns
    -------
    sub-arrays : list of ndarrays
        A list of arrays with indicies of bins.

    '''
    bin_group = []
    for bin_col in bins:
        bin_group.append(np.unique(bin_col, return_inverse=True))
    sorted_keys, bins_as_ints = [bg[0] for bg in bin_group], [bg[1] for bg in bin_group]

    n_bins = [max(skeys) + 1 for skeys in sorted_keys]

    indicies = [[[]for j in range(n_bins[1])] for i in range(n_bins[0])]

    if init_index:
        for i, k_ in enumerate(zip(bins[0], bins[1])):
            indicies[k_[0]][k_[1]].append(i+init_index)
    else:
        for i, k_ in enumerate(zip(bins[0], bins[1])):
            indicies[k_[0]][k_[1]].append(i)

    indicies = [np.array([np.array(col) for col in row]) for row in indicies]
    return indicies


def run_function_chunked(bins, chunksize=10**6):
    """
    Compute bin groups using only numpy.

    Parameters
    ----------
    bins: array-like
        A 2d array of integer bin values to be grouped.
    chunksize: int
        The chunk size to be used to split the bin data.
    """
    nvals = bins[0].shape[0]
    echunks = np.arange(0, nvals, chunksize)

    ind_arr = []
    for l, h in zip(echunks[0:-1], echunks[1:]):
        print(f'computing rows {l}-{h}')
        inds = groupby_nd([bins[0][l:h].compute(), bins[1][l:h].compute()], init_index=l)
        ind_arr.append(inds)
    return ind_arr


#@nb.jit(nopython=True, nogil=True, cache=True)
def combine_ind_chunks(idx_list_chunks):
    '''
    Combine function for lists of indicies generated by two-dimensional
    groupby-split function.

    Parameters:
    ind_list: array-like
    A tuple of two-dimensional tuples, each containing the list
    of inds corresponding to the unique pairs of two parameters (see
    groupby_nd function).

    Returns
    -------
    sub-arrays: list of ndarrays
        A list of arrays with indicies of bins.
    '''

    x_max = np.max([len(x_dim) for x_dim in idx_list_chunks])
    y_max = np.max([len(x_dim[0]) for x_dim in idx_list_chunks])

    idx_list_cat = [[[]for j in range(y_max)] for i in range(x_max)]

    for ind_list in idx_list_chunks:
        for i, inds in enumerate(ind_list):
            for j, inds_ in enumerate(inds):
                idx_list_cat[i][j] += list(inds_)

    idx_list_cat = [np.array([np.array(col) for col in row]) for row in idx_list_cat]

    return idx_list_cat


#@nb.jit(nopython=True, nogil=True, cache=True)
def find_ind_ranges(group_idx):
    '''
    Reduce bin indicies to index ranges.  Used to determine index ranges
    for each bin to determine block size or for assessing sortability.


    Parameters
    ----------
    ind_set: array-like
        Array with shape (K, N1, N2) where K is the number of blocks, (N1,
        N2) are the number of bins in each dimension.

    Returns
    -------
    sub-arrays : list of ndarrays
        A list of arrays with index ranges for each bin.
    '''

    group_ranges = [[[0, 0] for j in range(len(group_idx[0]))] for i in range(len(group_idx))]

    for i, inds in enumerate(group_idx):
        for j, inds_ in enumerate(inds):
            if len(inds_):
                group_ranges[i][j][0] = min(inds_)
                group_ranges[i][j][1] = max(inds_)

    group_ranges = [np.array([np.array(col) for col in row]) for row in group_ranges]
    return group_ranges


#@nb.jit(nopython=True, nogil=True, cache=True)
def groupby_nd_wrap(dd_bins, init_index=0):
    """
    Wrap the groupby_nd function to parse dask arrays to numpy like.

    Parameters
    ----------
    dd_bins: array-like
        A 2d dask array of integer bin values to be grouped.

    """
    bins = [dd_bins[:,0], dd_bins[:,1]]
    res = groupby_nd(bins, init_index)
    return res


#@nb.jit(nopython=True, nogil=True, cache=True)
def group_bin_values(bins, values) -> tuple:
    '''
    Performs a groupby operation on two bin parameters and returns the list
    of indicies for mapping the unique groups to their positions.

    Parameters
    ----------
    bins: array-like
        An array or tuple containing two lists of bins values for two the
        parameters to be binned.
    init_index: int, optional
        Starting value for the indicies to use when iterating or chunking
        large lists of bins.

    Returns
    -------
    sub-arrays : list of ndarrays
        A list of arrays with indicies of bins.

    '''

    bin_group = []
    for bin_col in bins:
        bin_group.append(np.unique(bin_col, return_inverse=True))

    sorted_keys, bins_as_ints = [bg[0] for bg in bin_group], [bg[1] for bg in bin_group]

    n_bins = [int(max(skeys) + 1) for skeys in sorted_keys]

    indicies = [[[]for j in range(n_bins[1])] for i in range(n_bins[0])]

    for i, k_ in enumerate(zip(bins[0], bins[1], values)):
        indicies[k_[0]][k_[1]].append(np.absolute(k_[2]))

    indicies = [np.array([np.array(col) for col in row]) for row in indicies]
    return indicies


#@nb.jit(nopython=True, nogil=True, cache=True)
def group_bin_values_wrap(da_bins, da_vals):
    """
    Wrap the groupby_nd function to parse dask arrays to numpy like.

    Parameters
    ----------
    dd_data: array-like
        A dask array with two columns for integer bin values and one
        column for values that will be the argument for a function.

    """

    bins = [da_bins[:,0], da_bins[:,1]]
    res = group_bin_values(bins, da_vals)
    return res


#@nb.jit(nopython=True, nogil=True, cache=True)
def combine_group_values(val_list_chunks):
    '''
    Combine function for sets of values generated by two-dimensional
    groupby-split function.

    Parameters:
    val_list_chunks: array-like
    A tuple of two-dimensional tuples, each containing the list
    of values corresponding to the unique pairs of two parameters (see
    groupby_nd function).

    Returns
    -------
    val_list_cat: list of ndarrays
        A list of arrays with values of bins.
    '''

    x_max = np.max([len(x_dim) for x_dim in val_list_chunks])
    y_max = np.max([len(x_dim[0]) for x_dim in val_list_chunks])

    val_list_cat = [[[]for j in range(y_max)] for i in range(x_max)]

    for val_list in val_list_chunks:
        for i, vals in enumerate(val_list):
            for j, vals_ in enumerate(vals):
                val_list_cat[i][j] += list(vals_)

    val_list_cat = [np.array([np.array(col) for col in row]) for row in val_list_cat]

    return val_list_cat


#@nb.jit(nopython=True, nogil=True, cache=True)
def apply_to_groups(val_groups, function):
    '''
    Apply the provided function to reduce each bins values.

    Parameters
    ----------
    val_groups: array-like
        Array with shape (K, N1, N2) where K is the number of blocks, (N1,
        N2) are the number of bins in each dimension.

    Returns
    -------
    results : list of ndarrays
        A list of arrays with results for each bin.
    '''

    result = np.zeros([len(val_groups), len(val_groups[0])])

    for i, vals in enumerate(val_groups):
        for j, vals_ in enumerate(vals):
            if len(vals_):
                #print(i, j, function(vals_))
                result[i][j] = function(vals_)

    result = [np.array(row) for row in result]
    return result
